# Python入門者向けハンズオン #pynyumon に参加した

Pythonのことをもっと知りたいなあと思い、えいやっと初めてconnpass経由で勉強会に参加しました。休日を使っていますが案外疲れが取れるので、これからも定期的に参加していこうかなと思っています。

なお、何回も行われているイベントということで、今後の参考にもなれば、という意味も込めて書こうと思います。

## 0.目次

<!-- TOC -->

- [Python入門者向けハンズオン #pynyumon に参加した](#python-pynyumon)
    - [0.目次](#0)
    - [1.動機](#1)
    - [2.イベント内容](#2)
        - [2.1.イベントページより・・・](#21)
        - [2.2.オリジナルプロダクト開発](#22)
        - [2.3.作ったコード](#23)
        - [2.4.知見](#24)
    - [3.最後に](#3)

<!-- /TOC -->

## 1.動機

[前回の記事](http://m4usta13ng.hatenablog.com/entry/python_3_exam)にも書きましたが、 [Python 3 エンジニア認定基礎試験](https://www.pythonic-exam.com/exam/basic)に合格したのですが、じゃあ実際に使えるレベルですか？というとそうではないなあ、という自覚があったので、ゆくゆくは仕事でも自分の生活を便利にするためでもどっちでもいいので何かに活用したいなあ、という目的に従い、勉強会に参加することにしました。

また、ここ半年そこそこ忙しい＆本格的な開発業務を初経験していたこともあり、なかなか勉強会や業務時間外の活動、勉強に時間を割くことが出来ていなかったので、そろそろ慣れてきたということもあり、もう一回自分の成長を考えという動機もありました。

## 2.イベント内容

入門者向け、といっても、世の中「入門」という言葉一つとっても色々なレベルに分かれていて、実はとっても難しい、ということもザラにあったりします。ということで、今回はどういった内容なのか、ということを書いておきます。

### 2.1.イベントページより・・・

[Python入門者向けハンズオン #7](https://python-nyumon.connpass.com/event/83667/)

イベントページの内容にもある通り、ハンズオンとしては、

- かんたんなPythonの言語仕様
- サードパーティパッケージの使い方（`pip`コマンド）
- スクレイピング（`requests`の使い方/`BeautifulSoup4`の使い方/サイトをスクレイピングする）

といった内容。2~3時間で[チュートリアルドキュメント](https://docs.python.jp/3.6/tutorial/)の内容をさらっていくので、ある程度勉強しておいて助かった、と息を吐きました（吐きました？）。

ハンズオン資料はイベントページから飛べるようになっています。

### 2.2.オリジナルプロダクト開発

残りは、ハンズオンで覚えたことを参考に、参加者が思い思いにプログラムを作成する時間が取られました。ほとんどの参加者はスクレイピングを色々なサイトで試す、といった感じに落ち着いていたようです。

私もスクレイピングを、ハンズオン中のサンプルコードを基にして、[新日本プロレスの選手一覧ページ](http://www.njpw.co.jp/profiles)から選手名一覧を取得し標準出力するプログラムを作成しました。作成しながら色々と引っかかったのが、

- HTMLコードを辿っていくので、意外と地道な作業になる。作業中には案外インタプリタが役に立った。
- HTML上はそんなことがない（はず）なのに、なぜか同じ選手名が2回3回取得された。順序もHTMLとは異なる表示順になったり（リストに格納したのでそうなるとは・・・）、まだまだ分からないことが多かった。
- もうすこし時間があれば、CSVやJSONファイルに保存する、という所まで行きたかったが、時間切れに。

上記などの問題があったので、復習していく中で解消できればと思っています。

### 2.3.作ったコード

一応・・・

```test_njpw.py
import requests
from bs4 import BeautifulSoup


def main():
    """
    新日本プロレスHPの選手一覧ページから、選手名リストを取得し、
    1人ずつ出力する。
    """

    url = 'http://www.njpw.co.jp/profiles'

    response = requests.get(url)

    content = response.content

    soup = BeautifulSoup(content, 'html.parser')

    # 選手名を含む<span>タグリストを全件取得
    wrestlers = soup.find_all('span', class_='name')

    # 表示用リストを宣言する
    wrestler_name_list = []

    # この時点ではまだ<span>タグなどが残っているので、
    # 選手名を抜き出し、リストに格納する
    for wrestler in wrestlers:
        wrestler_name = wrestler.get_text()
        if (wrestler_name not in wrestler_name_list):
            wrestler_name_list.append(wrestler_name)

    # 出力する。print_countは改行などに使うカウント
    print_count = 1
    for name in wrestler_name_list:
        if (print_count % 10 == 0):
            print(print_count, name)
        elif (wrestler_name_list[-1] == name):
            print(print_count, name, end='')
        else:
            print(print_count, name, end=', ')
        print_count += 1


if __name__ == '__main__':
    main()
```

1時間弱ではここまでしか書けませんでした。

### 2.4.知見

- `pip`の使い方は全然分かっていなかったので助かりました。
- 仮想環境周りは初めて知ることが多かったです。開発ごとに別の仮想環境を作成し、ライブラリを管理するなど、言われてみればそうだな、ということでもここまで分かっていなかったので、人から聴く大事さを痛感しました。。
- 参加者は学生や社会人、自分よりも大分先輩の方や、仕事では使う予定がないけど学びたい、という方も参加していました。Pythonが注目を集めていることを実感しました。
- 数か月後に初心者向けLTがあるということなので、これに参加するために自分で作業を行いたいと思います。

## 3.最後に

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">3班目: プロセスの選手一覧を取ってこようとした。同じ選手名が複数でてきたりして、if文で対応していたりしていた。  <a href="https://twitter.com/hashtag/pynyumon?src=hash&amp;ref_src=twsrc%5Etfw">#pynyumon</a></p>&mdash; かしゅー (@kashew_nuts) <a href="https://twitter.com/kashew_nuts/status/995214976729079808?ref_src=twsrc%5Etfw">2018年5月12日</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

誤：）プロレス 正：）プロレス